{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing News Articles with the T5 Model"
      ],
      "metadata": {
        "id": "CAuqiuOqa4Sz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imgkKguuXjo1",
        "outputId": "d63320c3-0260-4b04-f6aa-76c313c6c34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we are using the T5 model to perform text summarization on a news article. We start by sending a request to the URL of the news article and getting the HTML response. Then, we use the BeautifulSoup library to parse the HTML and extract the main text of the article.\n",
        "\n",
        "Next, we encode the text using the T5 tokenizer and set the model to evaluation mode. We then generate a summary of the text by calling the `model.generate()` method and specifying the maximum length of the summary. Finally, we decode the summary and remove the start and end tokens to get the final summary.\n",
        "\n",
        "Overall, this example demonstrates how to use the T5 model to summarize the main text of a news article in Python. You can customize the length of the summary or use a different variant of the T5 model by adjusting the code accordingly."
      ],
      "metadata": {
        "id": "rU8TwX70ajxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Load the T5 model\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# Set the URL of the news article\n",
        "url = \"https://edition.cnn.com/2022/12/24/world/new-minerals-discovered-in-el-ali-meteorite-scn/index.html\"\n",
        "\n",
        "# Send a request to the URL and get the HTML response\n",
        "response = requests.get(url)\n",
        "html = response.text\n",
        "\n",
        "# Use BeautifulSoup to parse the HTML and extract the main text\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "article = soup.find('article')\n",
        "\n",
        "# Set the input text and the maximum length of the summary\n",
        "text = article.text\n",
        "max_length = 20\n",
        "\n",
        "# Encode the input text and set the model to evaluation mode\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "model.eval()\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(input_ids, \n",
        "                             max_length=max_length)\n",
        "\n",
        "# Decode the summary and remove the start and end tokens\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Find the position of the final dot in the summary\n",
        "dot_pos = summary.rfind(\".\")\n",
        "\n",
        "# Truncate the summary at the final dot\n",
        "if dot_pos > 0:\n",
        "    summary = summary[:dot_pos+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pI7DvL0XltI",
        "outputId": "8396b79d-d85d-41d0-c507-1886e97f53e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary.capitalize()"
      ],
      "metadata": {
        "id": "dR4Bu9S9XmDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0aa0c131-58c8-41dd-9636-6bb7daa5c0d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Scientists have identified two minerals that don't naturally form on earth.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}